# 每日论文速递 - 2026-01-07

**更新日期**: 2026-01-07

---

## 1. 通过提示优化与学习集成实现鲁棒的人物感知毒性检测

- **原文链接**: http://arxiv.org/abs/2601.02337v1
- **发布日期**: 2026-01-05
- **摘要**:

毒性检测本质上具有主观性，其判断标准受到不同人口群体多元视角与社会先验认知的影响。尽管经济学和社会科学中采用的"多元主义"建模方法旨在捕捉不同情境下的观点差异，但当前大语言模型（LLM）的提示技术在不同角色设定和基础模型间会产生差异化结果。本研究对角色感知的毒性检测进行了系统性评估，结果表明：包括我们提出的自动化提示优化策略在内，没有任何单一提示方法能在所有模型-角色组合中保持绝对优势。为利用互补性误差，我们探索了四种提示变体的集成方法，并提出一种轻量级元集成策略：基于四维提示预测向量的支持向量机（SVM）集成。实验结果表明，所提出的SVM集成方法在各类角色设定中持续优于单一提示方法及传统多数投票技术，实现了跨角色场景下的最优综合性能。本研究首次系统比较了角色条件提示在毒性检测中的应用，并为主观性自然语言处理任务中的多元评估提供了稳健方法。

---

## 2. 估算文本温度

- **原文链接**: http://arxiv.org/abs/2601.02320v1
- **发布日期**: 2026-01-05
- **摘要**:

自回归语言模型在推理时通常使用温度参数来调整概率分布，从而控制生成文本的随机性。文本生成后，可通过最大似然估计法反推该参数值。基于此，我们提出一种针对任意文本（包括人类撰写的文本）在给定语言模型下的温度估计算法。我们评估了多种中小型大语言模型的温度估计能力，并选用表现最优的Qwen3 14B模型对主流语料库进行了温度估计。

---

## 3. 大语言模型中的二次幂量化感知训练（PoT-QAT）

- **原文链接**: http://arxiv.org/abs/2601.02298v1
- **发布日期**: 2026-01-05
- **摘要**:

在大型语言模型（LLMs）中，参数量在过去几年呈指数级增长，例如从GPT-2的15亿参数增至GPT-3的1750亿，更高版本甚至可能突破万亿规模。这给实际部署带来了巨大挑战，尤其在边缘设备上。与云计算不同，边缘设备的存储和计算能力极为有限，因此需要开发创新方法以实现此类应用。本研究探索了一种特殊的量化压缩方法，将权重值限制为仅二的幂次方（PoT）。该方法通过仅存储指数显著节省内存空间，更重要的是能以低成本位移运算替代昂贵的乘法操作，大幅降低计算开销。为克服严格量化导致的性能损失，我们采用量化感知训练（QAT）通过额外训练提升模型表现。在GPT-2 124M模型上的实验表明，经过额外训练的PoT量化模型性能显著提升：困惑度改善66%，与基准GPT-2相比BERT-Score损失仅为1%。预计该方法可节省87.5%的内存占用，且推理速度较全精度模型提升3-10倍。

---

