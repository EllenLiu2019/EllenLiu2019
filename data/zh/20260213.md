# 每日论文速递 - 2026-02-13

**更新日期**: 2026-02-13

---

## 1. 权重衰减提升语言模型可塑性

- **原文链接**: http://arxiv.org/abs/2602.11137v1
- **发布日期**: 2026-02-11
- **摘要**:

当前大型语言模型（LLM）开发的主流范式是先预训练基础模型，再通过进一步训练提升性能并优化模型行为。然而，现有关于超参数优化与缩放定律的研究主要基于基础模型验证损失的角度，忽略了下游任务适应性的考量。本研究从模型可塑性——即基础模型通过微调成功适应下游任务的能力——这一视角重新审视预训练过程。我们重点关注权重衰减这一预训练中关键的正则化参数作用。通过系统性实验，我们发现采用较大权重衰减值训练的模型具有更强的可塑性，这意味着它们在下游任务微调时能获得更大的性能提升。这一现象可能导致反直觉的权衡：预训练后表现较差的基础模型，经过微调后反而可能表现更优。对权重衰减影响模型行为机制的进一步研究表明，它能促进线性可分表征的形成，规范注意力矩阵，并减少对训练数据的过拟合。总之，本研究证明了在超参数优化中需要采用超越交叉熵损失的评估指标的重要性，并揭示单一优化超参数在塑造模型行为中发挥的多重作用。

---

## 2. GameDevBench：通过游戏开发评估智能体能力

- **原文链接**: http://arxiv.org/abs/2602.11103v1
- **发布日期**: 2026-02-11
- **摘要**:

尽管编码智能体发展迅速，但其多模态版本的研究进展却相对滞后。核心挑战在于缺乏能够同时评估软件开发复杂性与深度多模态理解能力的测试平台。游戏开发恰好提供了这样的平台——智能体不仅需要驾驭庞大而密集的代码库，还必须在可视化游戏场景中处理着色器、精灵图、动画等本质多模态的素材。我们推出首个面向游戏开发任务的智能体评估基准GameDevBench，该基准包含132项源自网络与视频教程的任务。这些任务要求显著的多模态理解能力且复杂度极高：平均解决方案所需的代码行数与文件修改量，是现有软件开发基准任务的三倍以上。

当前智能体在游戏开发任务中仍面临巨大挑战，表现最佳的智能体仅能完成54.5%的任务。研究发现，任务感知难度与多模态复杂度呈强相关性：在游戏玩法导向任务中成功率为46.9%，而在涉及2D图形处理的任务中骤降至31.6%。为提升多模态能力，我们为智能体引入两种基于图像与视频的简易反馈机制。尽管方法简单，这些机制能持续提升性能表现，其中Claude Sonnet 4.5模型的改进最为显著——任务完成率从33.3%提升至47.7%。我们公开开放GameDevBench基准，以支持智能体游戏开发领域的进一步研究。

---

## 3. 大型语言模型能让每个人都满意吗？

- **原文链接**: http://arxiv.org/abs/2602.11091v1
- **发布日期**: 2026-02-11
- **摘要**:

大型语言模型（LLM）中的错位问题，指的是模型无法同时满足安全性、价值观与文化维度的要求，导致在现实场景中这些维度必须共存时，其行为偏离人类预期。现有基准测试如SAFETUNEBED（以安全为中心）、VALUEBENCH（以价值观为中心）和WORLDVIEW-BENCH（以文化为中心）主要孤立评估各维度，因而对其相互作用与权衡的洞察有限。近期研究如基于机制可解释性的MIB和INTERPRETABILITY BENCHMARK虽为模型失效提供了宝贵视角，但仍不足以系统刻画跨维度权衡关系。为填补这些空白，我们提出MisAlign-Profile——一个受机制剖析启发的统一基准测试框架，用于衡量错位权衡。

首先，我们构建了MISALIGNTRADE数据集，涵盖112个规范性领域分类（包括14个安全领域、56个价值观领域和42个文化领域），包含错位与对齐的英文数据。除领域标签外，每个提示均通过Gemma-2-9B-it模型归类为三种正交语义类型之一（对象错位、属性错位或关系错位），并借助Qwen3-30B-A3B-Instruct-2507模型扩展数据，同时采用基于SimHash的指纹技术避免重复。通过两阶段拒绝采样，每个提示均配有错位与对齐的响应，以确保数据质量。

其次，我们在MISALIGNTRADE上对通用模型、微调模型及开源权重LLM进行基准测试，结果显示各维度间存在12%-34%的错位权衡。

---

