# 每日论文速递 - 2025-12-14

**更新日期**: 2025-12-14

---

## 1. 异步推理：免训练交互式思维大语言模型

- **原文链接**: http://arxiv.org/abs/2512.10931v1
- **发布日期**: 2025-12-11
- **摘要**:

许多先进的LLM被训练为在给出答案前先进行思考。推理能力能显著提升语言模型的能力与安全性，但也降低了其交互性：面对新的输入时，模型必须停止思考才能作出回应。现实应用场景（如语音助手或嵌入式助手）要求LLM智能体能够实时响应并适应新增信息，这与顺序交互模式存在根本矛盾。相比之下，人类可以异步地倾听、思考和行动：我们会在阅读问题时开始思考，并在组织答案时持续思考。本研究通过增强具备推理能力的LLM，使其无需额外训练即可实现类似异步运作。我们的方法利用旋转嵌入的特性，使原本设计用于顺序交互的LLM能够同步执行思考、倾听和生成输出的任务。通过在数学推理、常识推理和安全推理任务上的评估，我们发现该方法能实时生成准确的思考增强型答案，将首个非思考标记的生成时间从数分钟缩短至≤5秒，整体实时延迟降低6-11倍。

---

## 2. CompanionCast：一款集成空间音频的多智能体对话AI框架，专为社交共览体验设计

- **原文链接**: http://arxiv.org/abs/2512.10918v1
- **发布日期**: 2025-12-11
- **摘要**:

社交临场感是共同观看内容获得愉悦体验的核心要素，然而现代媒体消费日益趋向个体化。本研究探讨多智能体对话式AI系统能否在不同内容类型中重现共享观看体验的动态交互。我们提出CompanionCast——一个通用框架，通过协调多个角色专精的AI智能体，使其能够基于多模态输入、语音合成与空间音频技术对视频内容作出响应。该框架的独特之处在于整合了"LLM即裁判"模块，可从相关性、真实性、参与度、多样性、人格一致性五个维度迭代评分并优化对话质量。我们以体育观看这一具有丰富动态性与深厚社交传统的领域进行验证：针对足球迷的初步研究表明，与单人观看相比，多智能体交互能显著提升感知社交临场感。本研究的贡献在于：（1）提出面向多模态视频内容的多智能体对话协调通用框架；（2）构建用于对话质量控制的新型评估者-智能体协作流程；（3）为AI媒介化共同观看提升社交临场感提供探索性证据。最后，我们讨论了将该方法应用于娱乐、教育及协作观看等多样化场景所面临的挑战与未来发展方向。

---

## 3. 多模态大语言模型下的计算情感分析：一项新兴方法论机遇的当前证据

- **原文链接**: http://arxiv.org/abs/2512.10882v1
- **发布日期**: 2025-12-11
- **摘要**:

情感在政治中占据核心地位，分析情感在政治传播中的作用具有悠久传统。随着研究越来越多地利用视听材料来分析情感表达，多模态生成式人工智能的出现预示着巨大进步。然而，我们尚缺乏关于多模态AI在情感分析中有效性的证据。本文通过评估当前多模态大语言模型在两类人类标注视频数据集中的情绪唤醒度分析表现，填补了这一研究空白。研究发现，在理想条件下，多模态大语言模型的情绪唤醒度评分具有高度可靠性，且几乎未显示出人口统计学偏差迹象。但在现实议会辩论场景的演讲者视频记录中，多模态大语言模型的唤醒度评分未能实现预期效果，可能对后续统计推断产生负面影响。因此，本研究强调了对新兴生成式AI方法在政治分析领域进行持续深入评估的必要性，并提供了一个可复现的评估框架。

---

