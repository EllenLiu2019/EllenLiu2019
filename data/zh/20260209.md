# 每日论文速递 - 2026-02-09

**更新日期**: 2026-02-09

---

## 1. DFlash：面向闪存推测解码的块扩散技术

- **原文链接**: http://arxiv.org/abs/2602.06036v1
- **发布日期**: 2026-02-05
- **摘要**:

自回归大语言模型（LLMs）虽具备强大性能，但其固有的顺序解码机制导致推理延迟高、GPU利用率低。推测解码技术通过使用快速草稿模型生成输出，并由目标大语言模型并行验证来缓解这一瓶颈；然而现有方法仍依赖自回归式草稿生成，本质上仍是顺序执行，限制了实际加速效果。扩散大语言模型通过并行生成提供了有前景的替代方案，但当前扩散模型性能通常弱于自回归模型。本文提出DFlash——一种采用轻量级块扩散模型进行并行草稿生成的推测解码框架。该框架通过单次前向传播生成草稿词元，并基于从目标模型提取的上下文特征对草稿模型进行条件约束，实现了高质量输出与高接受率的高效草稿生成。实验表明，DFlash在多种模型与任务上实现了超过6倍的无损加速，相比当前最先进的推测解码方法EAGLE-3提速高达2.5倍。

---

## 2. 学习面向运行时智能体记忆的查询感知预算层级路由

- **原文链接**: http://arxiv.org/abs/2602.06025v1
- **发布日期**: 2026-02-05
- **摘要**:

随着大语言模型（LLM）智能体在超越单一上下文窗口的场景中运行，内存的重要性日益凸显，但现有系统大多依赖离线、查询无关的内存构建方式，这种方式效率低下且可能丢失查询关键信息。尽管运行时内存利用是一种自然的替代方案，但先前的研究往往带来显著开销，且对性能与成本的权衡缺乏明确的控制机制。本研究提出 **BudgetMem**——一个支持显式、查询感知的性能-成本控制的运行时智能体内存框架。BudgetMem将内存处理构建为一组内存模块，每个模块提供三种预算层级（即低/中/高）。轻量级路由器通过强化学习训练的紧凑神经策略，在模块间执行预算层级路由，以平衡任务性能与内存构建成本。以BudgetMem作为统一测试平台，我们研究了实现预算层级的三种互补策略：实现方式（方法复杂度）、推理行为（推断模式）和容量（模块模型规模）。在LoCoMo、LongMemEval和HotpotQA数据集上的实验表明，当优先考虑性能时（即高预算设置），BudgetMem优于现有基线方法；在更严格的预算约束下，也能提供更优的精度-成本边界。此外，我们的分析揭示了不同层级策略的优缺点，明确了在不同预算区间内各策略维度何时能实现最有利的权衡。

---

## 3. 大型语言模型在创伤后应激障碍严重程度评估中的系统性评价：情境知识与建模策略的作用

- **原文链接**: http://arxiv.org/abs/2602.06015v1
- **发布日期**: 2026-02-05
- **摘要**:

大型语言模型正日益以零样本方式应用于心理健康状况评估，但我们对其准确性影响因素的认识仍有限。本研究利用包含1,437名受试者的临床数据集（含自然语言叙述文本及自评创伤后应激障碍严重程度分数），对11个前沿大型语言模型进行了系统性评估。为探究影响准确性的因素，我们系统性地调整了：（一）背景知识要素，如子量表定义、数据分布摘要及访谈问题；（二）建模策略要素，包括零样本与少样本学习、推理强度、模型参数量、结构化子量表与直接标量预测、输出重标度及九种集成方法。研究发现：（a）当提供详细构念定义和叙述背景时，模型准确性最高；（b）增强推理强度可提升评估精度；（c）开源模型（Llama、Deepseek）在参数量超过700亿后性能趋于饱和，而闭源模型（o3-mini、gpt-5）随版本迭代持续改进；（d）将有监督模型与零样本大语言模型集成时获得最优性能。综合结果表明，背景知识的选择与建模策略的制定对于部署大语言模型实现精准心理健康评估至关重要。

---

