# 每日论文速递 - 2025-12-04

**更新日期**: 2025-12-04

---

## 1. 道德一致性管道：大型语言模型的持续伦理评估

- **原文链接**: http://arxiv.org/abs/2512.03026v1
- **发布日期**: 2025-12-02
- **摘要**:

大型语言模型（LLM）的快速发展和适应性凸显了道德一致性的必要性——即在多样化情境中保持伦理推理连贯性的能力。现有的对齐框架（旨在使模型行为与人类伦理及社会规范保持一致的结构化方法）通常依赖静态数据集和事后评估，难以揭示伦理推理在不同情境或时间尺度下的演变机制。本研究提出道德一致性管道（MoCoP），一种无需数据集、闭环式的框架，用于持续评估和解释LLM的道德稳定性。MoCoP在自持式架构中整合了三个支撑层：（i）词汇完整性分析，（ii）语义风险估计，以及（iii）基于推理的判断建模，能够自主生成、评估和优化伦理场景而无需外部监督。我们在GPT-4-Turbo和DeepSeek上的实验结果表明，MoCoP能有效捕捉纵向伦理行为，揭示伦理维度与毒性维度间的强负相关关系（相关系数rET = -0.81，p值小于0.001），以及与响应延迟近乎零关联（相关系数rEL约等于0）。这些发现表明，道德一致性与语言安全性往往作为模型行为稳定且可解释的特征显现，而非短期波动。此外，通过将伦理评估重构为动态、模型无关的道德内省形式，MoCoP为可扩展的持续审计提供了可复现的基础，并推动了自主AI系统中计算道德研究的发展。

---

## 2. LORE：面向搜索相关性的大规模生成模型

- **原文链接**: http://arxiv.org/abs/2512.03025v1
- **发布日期**: 2025-12-02
- **摘要**:

成果。我们提出了LORE，一个面向电商搜索场景的大生成模型相关性系统化框架。经过三年部署与迭代，LORE在线上GoodRate指标上累计提升达27%。本报告将分享其从数据、特征、训练、评估到部署全生命周期中积累的宝贵经验。洞察。现有研究虽尝试通过思维链技术提升相关性，但常遭遇性能瓶颈。我们认为其根源在于将相关性视为单一任务，缺乏系统性解构。我们的核心洞见是：相关性由知识推理、多模态匹配、规则遵循三大独立能力构成。主张通过质化驱动的能力解构突破当前性能天花板。贡献。LORE为LLM相关性全生命周期提供了完整蓝图，主要贡献包括：（1）融合SFT渐进式思维链合成与RL人类偏好对齐的两阶段训练范式；（2）针对核心能力评估设计的综合基准RAIR；（3）基于查询频次分层的部署策略，实现离线LLM能力向线上系统的高效迁移。LORE既是实用解决方案，也可为其他垂直领域提供方法论参考。

---

## 3. 微调大型语言模型实现逻辑翻译：利用Lang2Logic减少幻觉现象

- **原文链接**: http://arxiv.org/abs/2512.02987v1
- **发布日期**: 2025-12-02
- **摘要**:

自然语言处理（NLP）领域的最新进展，尤其是大语言模型（LLM）的发展，推动了无需人工干预的自然语言语句自动形式逻辑翻译。这项技术能够实现自动化推理，并有助于软件系统中的调试、寻找循环不变式以及遵循规范。然而，LLM产生的幻觉（即错误输出）对需要精确性的逻辑翻译任务构成了挑战。本研究提出了一种新颖框架，该框架输入英语句子，将其转换为逻辑表达式，再翻译为合取范式（CNF）以进行可满足性求解。该框架采用经典NLP技术，结合自定义语法、符号计算库以及微调的语言模型来减少幻觉。在早期实验中我们观察到，经过不同语法设置训练的微调模型能够有意识地修正原始模型产生的同类幻觉，从而提供可靠的CNF生成。

---

