# 每日论文速递 - 2026-01-19

**更新日期**: 2026-01-19

---

## 1. MatchTIR：通过二分匹配实现工具集成推理的细粒度监督

- **原文链接**: http://arxiv.org/abs/2601.10712v1
- **发布日期**: 2026-01-15
- **摘要**:

工具集成推理（TIR）通过将推理步骤与外部工具交互交织，赋能大语言模型（LLMs）处理复杂任务。然而，现有的强化学习方法通常依赖结果级或轨迹级奖励，对轨迹中的所有步骤赋予统一的优势值。这种粗粒度的信用分配无法区分有效工具调用与冗余或错误调用，尤其在长跨度多轮交互场景中更为突出。为此，我们提出MatchTIR框架，通过基于二分图匹配的轮次级奖励分配和双层级优势估计机制，实现细粒度监督。具体而言，我们将信用分配建模为预测轨迹与真实轨迹间的二分图匹配问题，采用两种分配策略生成密集的轮次级奖励。此外，为平衡局部步骤精度与全局任务成功率，我们设计了融合轮次级与轨迹级信号的双层级优势估计方案，为每个交互轮次分配差异化的优势值。在三个基准测试上的大量实验证明了MatchTIR的优越性。值得注意的是，我们的40亿参数模型在多数任务中超越了80亿参数的竞品模型，尤其在长跨度多轮任务中表现突出。代码已开源：https://github.com/quchangle1/MatchTIR。

---

## 2. 将智能体记忆锚定于情境意图

- **原文链接**: http://arxiv.org/abs/2601.10702v1
- **发布日期**: 2026-01-15
- **摘要**:

在长周期、目标导向的交互中部署大语言模型仍面临挑战，因为相似的实体和事实会在不同的潜在目标与约束条件下重复出现，导致记忆系统检索到上下文不匹配的证据。我们提出STITCH（上下文历史中的结构化意图追踪）——一种智能记忆系统，它通过结构化检索线索（即上下文意图）为每个轨迹步骤建立索引，并依据当前步骤的意图匹配检索历史。上下文意图提供紧凑的信号以消除重复提及的歧义并减少干扰，包括：（1）定义主题片段的当前潜在目标；（2）动作类型；（3）锚定关键属性的显著实体类型。在推理过程中，STITCH根据意图兼容性对记忆片段进行筛选和排序，抑制语义相似但上下文不兼容的历史信息。

为评估系统性能，我们提出了CAME-Bench——一个面向现实、动态、目标导向轨迹的上下文感知检索基准测试。在CAME-Bench和LongMemEval的实验中，STITCH实现了最先进的性能表现，以35.6%的优势超越最强基线模型，且随着轨迹长度增加，其优势进一步扩大。分析表明，意图索引显著降低了检索噪声，这为支持意图感知记忆、实现鲁棒的长周期推理提供了有力支撑。

---

## 3. LIBERTy：基于结构反事实的LLM概念解释基准因果框架

- **原文链接**: http://arxiv.org/abs/2601.10700v1
- **发布日期**: 2026-01-15
- **摘要**:

基于概念的解释方法能够量化高级概念（如性别或经验）如何影响模型行为，这对高风险领域的决策者至关重要。近期研究通过将这类解释与基于反事实估计的参考因果效应进行比较，来评估其忠实度。实践中，现有基准依赖成本高昂的人工撰写反事实作为不完美的替代方案。为解决这一问题，我们提出了一个构建包含结构化反事实对数据集的框架：LIBERTy（基于LLM的可解释性干预基准与参考目标）。该框架以明确定义的文本生成结构化因果模型为基础，通过对概念进行干预，使影响沿因果模型传递，直至大语言模型生成反事实文本。我们发布了三个数据集（疾病检测、简历筛选和工作场所暴力预测）及新评估指标——顺序忠实度。基于这些资源，我们在五个模型上评估了多种方法，发现基于概念的解释方法仍有巨大改进空间。LIBERTy还能系统分析模型对干预的敏感性：我们发现专有大语言模型对人口统计概念的敏感性显著降低，这很可能源于训练后的缓解措施。总体而言，LIBERTy为开发忠实可靠的可解释性方法提供了亟需的基准框架。

---

