# 每日论文速递 - 2025-12-11

**更新日期**: 2025-12-11

---

## 1. 重探大型语言模型训练中下游指标的缩放特性

- **原文链接**: http://arxiv.org/abs/2512.08894v1
- **发布日期**: 2025-12-09
- **摘要**:

传统上，大语言模型（LLM）的缩放定律主要关注预训练损失等代理指标，而预测下游任务性能一直被认为不可靠。本文通过提出一种直接建模训练预算与基准性能缩放关系的框架，对这一观点提出了挑战。我们发现，在固定词元-参数比的情况下，简单的幂律关系能够准确描述多个热门下游任务的对数准确率缩放行为。实验结果表明，这种直接建模方法比先前提出的两阶段流程具有更好的外推能力，后者容易产生误差累积问题。此外，我们引入了能够跨词元-参数比预测准确率、并考虑重复采样下推理计算量的函数形式。我们在两个数据集混合上训练了参数量高达170亿、训练词元量达3500亿的模型，验证了这些发现。为支持可复现性并促进未来研究，我们公布了完整的预训练损失和下游评估结果集。

---

## 2. 迈向基于稀疏自编码器的忠实检索增强生成

- **原文链接**: http://arxiv.org/abs/2512.08892v1
- **发布日期**: 2025-12-09
- **摘要**:

检索增强生成（RAG）通过将输出建立在检索证据的基础上，提升了大型语言模型（LLM）的事实准确性，但生成内容与提供来源相矛盾或超出范围的忠实性失效问题，仍是关键挑战。现有的RAG幻觉检测方法通常依赖大规模检测器训练（需要大量标注数据）或调用外部LLM评判器（导致高昂推理成本）。尽管部分方法尝试利用LLM内部表征进行幻觉检测，其准确性仍有限制。受近期机制可解释性进展的启发，我们采用稀疏自编码器（SAE）解耦内部激活，成功识别出在RAG幻觉期间被特异性触发的特征。基于信息驱动的特征选择与加性特征建模的系统化流程，我们提出了RAGLens——一种利用LLM内部表征精准标记不忠实RAG输出的轻量级幻觉检测器。RAGLens不仅相比现有方法实现了更优的检测性能，还能提供可解释的决策依据，从而有效实现不忠实RAG的事后修正。最后，我们论证了设计选择的合理性，并揭示了LLM中幻觉相关信号分布的新洞见。代码已开源：https://github.com/Teddy-XiongGZ/RAGLens。

---

## 3. 提问、回答与检测：基于问题条件专家混合模型的角色扮演大语言模型用于人格检测

- **原文链接**: http://arxiv.org/abs/2512.08814v1
- **发布日期**: 2025-12-09
- **摘要**:

理解人类个性对于个性化推荐和心理健康评估等网络应用至关重要。现有的人格检测研究主要采用"帖子→用户向量→标签"的建模范式，将社交媒体帖子编码为用户表征以预测人格标签（如MBTI标签）。尽管大语言模型的最新进展提升了文本编码能力，但由于标签稀缺性以及用户语言与抽象心理构念之间语义映射关系不明确，这些方法仍受限于有限的监督信号。为应对这些挑战，我们提出ROME框架，将心理学知识显式注入人格检测过程。受标准化自评测试启发，ROME利用大语言模型的角色扮演能力，模拟用户对经过验证的心理测量问卷的回答。这些生成的题目级答案将自由形式的用户帖子转化为可解释的、基于问卷的证据，从而建立语言线索与人格标签的关联，既通过丰富的中间监督缓解标签稀缺问题，又提供语义推理链以指导并简化文本到人格映射的学习。随后，一个基于题目条件的专家混合模块协同处理帖子和题目表征，在显式监督下学习回答问卷条目。预测答案被汇总为可解释的答案向量，并与用户表征在多任务学习框架中融合进行最终预测，其中问卷回答任务作为人格检测的强大辅助任务。在两个真实数据集上的大量实验表明，ROME始终优于现有最先进基线模型（在Kaggle数据集上提升15.41%）。

---

