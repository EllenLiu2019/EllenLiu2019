# 每日论文速递 - 2026-01-04

**更新日期**: 2026-01-04

---

## 1. AdaGReS：面向令牌预算检索增强生成的冗余感知评分自适应贪婪上下文选择

- **原文链接**: http://arxiv.org/abs/2512.25052v1
- **发布日期**: 2025-12-31
- **摘要**:

检索增强生成（RAG）对所选上下文的质量极为敏感，而标准的top-k检索常返回冗余或近似重复的文本块，既浪费标记预算又损害下游生成质量。我们提出AdaGReS——一种面向标记预算约束RAG的冗余感知上下文选择框架，该框架通过结合查询-文本块相关性得分与集合内冗余惩罚的集合级目标函数进行优化。AdaGReS在标记预算约束下，基于目标函数导出的边际增益执行贪心选择，并引入闭式实例自适应校准机制，动态调整相关性-冗余权衡参数，从而无需人工调参即可适应候选池统计特性与预算限制。我们进一步的理论分析表明，在实际嵌入相似性条件下，所提出的目标函数具有ε近似子模性，为贪心选择提供了近似最优性保证。在开放域问答（Natural Questions）和高冗余生物医学（药物）语料库上的实验表明，该方法在冗余控制与上下文质量方面持续改进，最终转化为更优的端到端答案质量及跨场景鲁棒性。

---

## 2. MAMA-Memeia！多维度多智能体协作识别表情包中的抑郁症状

- **原文链接**: http://arxiv.org/abs/2512.25015v1
- **发布日期**: 2025-12-31
- **摘要**:

近年来，表情包已从单纯的幽默交流媒介，演变为用户自由便捷表达多元情感的重要载体。随着表情包在抑郁情绪表达中的使用日益增长，我们针对社交媒体用户分享的表情包开展抑郁症状识别研究。我们推出RESTOREx作为关键资源，通过大语言模型生成与人工标注的解释说明，实现社交媒体表情包抑郁症状的检测。基于认知分析疗法（CAT）能力这一临床心理学方法，我们构建了MAMAMemeia协同多智能体多维度讨论框架。该框架将宏观F1值提升7.55%，在与30余种方法的对比中确立为全新性能基准。

---

## 3. 大型语言模型与英语的熵

- **原文链接**: http://arxiv.org/abs/2512.24969v1
- **发布日期**: 2025-12-31
- **摘要**:

我们利用大语言模型（LLM）从多种来源的英文文本中揭示长程结构。在许多情况下，条件熵或编码长度随上下文长度至少持续下降至约 $N\sim 10^4$ 字符量级，这意味着在这些距离上存在直接的依赖关系或相互作用。一个必然推论是：在这些间隔距离上字符之间存在微小但显著的相关性——我们通过独立于模型的数据验证了这一现象。编码长度的分布表明，随着 $N$ 增大，对字符的确定性认知逐渐显现为一种涌现现象。在模型训练过程中，我们观察到长短上下文长度下呈现不同的动态特征，这表明长程结构是逐步习得的。我们的研究结果为构建大语言模型或语言本身的统计物理模型提供了约束条件。

---

