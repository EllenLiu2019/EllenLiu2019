# 每日论文速递 - 2026-01-24

**更新日期**: 2026-01-24

---

## 1. 沙箱中的大语言模型激发通用智能体智能

- **原文链接**: http://arxiv.org/abs/2601.16206v1
- **发布日期**: 2026-01-22
- **摘要**:

我们提出"沙盒中的大语言模型"（LLM-in-Sandbox），使大语言模型能够在代码沙盒（即虚拟计算机）中进行探索，从而激发其在非代码领域的通用智能。我们首先证明，无需额外训练的强大大语言模型已具备利用代码沙盒处理非代码任务的泛化能力。例如，大语言模型能自发访问外部资源获取新知识，利用文件系统处理长上下文，并执行脚本来满足格式要求。我们进一步表明，通过"沙盒中的大语言模型强化学习"（LLM-in-Sandbox-RL），仅使用非智能体数据训练模型进行沙盒探索，即可增强这些智能体能力。实验表明，无论是免训练还是后训练设置，LLM-in-Sandbox在数学、物理、化学、生物医学、长上下文理解及指令遵循等方面均展现出稳健的泛化能力。最后，我们从计算和系统角度分析了LLM-in-Sandbox的效率，并将其开源为Python软件包以促进实际部署。

---

## 2. 教育应用中的LLM提示评估

- **原文链接**: http://arxiv.org/abs/2601.16134v1
- **发布日期**: 2026-01-22
- **摘要**:

随着大型语言模型在教育应用中的日益普及，如何基于实证方法设计和评估能够生成个性化且符合教学目标的提示词，已成为亟待解决的问题。本研究提出了一种可推广的系统化提示词评估方法，并通过分析结构化对话活动中LLM生成的后续提问进行实证演示。研究设计并测试了六种提示词模板，这些模板融合了成熟的提示工程模式，每种提示词侧重不同的教学策略。

通过适用于各类教育场景的锦标赛式评估框架，研究对提示词模板进行了比较。该评估采用Glicko2评分系统，由八位评审从格式规范性、对话支持度和学习者适配性三个维度对问题组进行评价。数据来源于三个独立教育场景中120组真实用户互动记录。

结果显示，在涉及策略性阅读的提示词模板在成对比较中以81%至100%的胜率显著优于其他模板。该提示词融合了角色设定与语境管理两种模式，旨在支持自主学习等元认知学习策略。本方法为教育技术研究者展示了如何系统评估并改进提示词设计，推动教育领域的提示工程从临时性设计向基于实证的规范化开发转变。

---

## 3. 通过语言特定模型融合提升训练效率与降低维护成本

- **原文链接**: http://arxiv.org/abs/2601.16127v1
- **发布日期**: 2026-01-22
- **摘要**:

针对特定任务的多语言大语言模型（LLM）进行微调时，通常需要在包含所有目标语言样本的多语言数据集上训练模型。若要对已支持的语言补充数据或新增语言支持，往往需要重新训练模型，这不仅计算效率低下，还会造成严重的维护瓶颈。近期关于多语言多任务模型融合的研究在提升质量方面展现出潜力，但其计算效率与维护成本尚未得到充分验证。本研究首次从效率角度对该融合策略展开专项分析，并在三项独立任务中进行评估。实验表明，该方法在保持质量相当的同时实现了显著的效率提升：融合策略使初始训练时间最高减少50%。在模型维护场景中，针对单一语言更新后重新融合的策略，相比重新训练完整多语言模型，可降低超过60%的训练成本。我们在公开数据集与行业专有数据集上的实验均证实，该方法不仅适用于学术界已有研究场景，在工业应用场景中同样表现优异。

---

