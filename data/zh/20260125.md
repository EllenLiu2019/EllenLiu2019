# 每日论文速递 - 2026-01-25

**更新日期**: 2026-01-25

---

## 1. 沙盒中的大语言模型激发通用智能体智能

- **原文链接**: http://arxiv.org/abs/2601.16206v1
- **发布日期**: 2026-01-22
- **摘要**:

我们提出"沙盒中的大语言模型"（LLM-in-Sandbox），使大语言模型能够在代码沙盒（即虚拟计算机）中进行探索，从而激发其在非代码领域的通用智能。我们首先证明，无需额外训练的强大大语言模型已具备利用代码沙盒处理非代码任务的泛化能力。例如，大语言模型能自发访问外部资源获取新知识，利用文件系统处理长上下文，并执行脚本来满足格式要求。我们进一步表明，通过"沙盒中的大语言模型强化学习"（LLM-in-Sandbox-RL），仅使用非智能体数据训练模型进行沙盒探索，即可增强这些智能体能力。实验表明，无论是免训练还是后训练设置下的LLM-in-Sandbox，在数学、物理、化学、生物医学、长上下文理解和指令遵循等方面均展现出稳健的泛化性能。最后，我们从计算和系统角度分析了LLM-in-Sandbox的效率，并将其开源为Python软件包以促进实际部署。

---

## 2. 教育应用中的LLM提示评估

- **原文链接**: http://arxiv.org/abs/2601.16134v1
- **发布日期**: 2026-01-22
- **摘要**:

随着大型语言模型在教育应用中的日益普及，亟需基于证据的方法来设计和评估能够生成个性化且符合教学目标的提示词。本研究提出了一种可推广的系统性提示词评估方法，并通过分析结构化对话活动中LLM生成的后续问题进行实证展示。研究设计并测试了六种提示词模板，这些模板融合了成熟的提示工程模式，每种提示词侧重不同的教学策略。

通过适用于各类教育场景的锦标赛式评估框架，研究者对这些提示词模板进行了比较。该评估采用Glicko2评分系统，由八位评委从格式规范性、对话支持度和学习者适配性三个维度对问题组进行评价。数据来源于三个独立教育场景中120组真实用户互动记录。

结果显示，强调策略性阅读的单一提示词模板在成对比较中以81%至100%的胜率显著优于其他模板。该提示词融合了角色设定与语境管理两种模式，旨在支持自主学习等元认知学习策略。本方法为教育技术研究者展示了如何系统评估和改进提示词设计，推动教育应用从临时性的提示工程转向基于证据的提示词开发模式。

---

## 3. 通过语言特定模型融合提升训练效率与降低维护成本

- **原文链接**: http://arxiv.org/abs/2601.16127v1
- **发布日期**: 2026-01-22
- **摘要**:

针对特定任务的多语言大语言模型（LLM）进行微调时，通常需要在包含所有目标语言样本的多语言数据集上训练模型。若要对已支持语言进行数据增补或添加新语言支持，往往需要重新训练整个模型，这种操作不仅计算效率低下，还会形成严重的维护瓶颈。近期关于多语言多任务模型融合的研究虽在质量提升方面展现出潜力，但其计算效率与维护成本问题尚未得到充分探讨。本研究首次从效率角度对这种融合策略进行聚焦分析，通过在三个独立任务上的评估验证其效能。实验表明，该融合方法在保持质量相当的同时能显著提升效率：初始训练时间最高可缩减50%。在模型维护场景中，针对单一语言更新后重新融合的策略，与重新训练完整多语言模型相比，可降低超过60%的训练成本。我们在公开数据集和行业专有数据集上的实验均证实，该方法不仅适用于学术界已研究的场景，在工业应用场景中同样表现优异。

---

