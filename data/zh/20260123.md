# 每日论文速递 - 2026-01-23

**更新日期**: 2026-01-23

---

## 1. 在对抗性情感攻击下利用大型语言模型进行鲁棒假新闻检测

- **原文链接**: http://arxiv.org/abs/2601.15277v1
- **发布日期**: 2026-01-21
- **摘要**:

虚假信息与假新闻已成为紧迫的社会挑战，亟需可靠的自动化检测方法。先前研究已强调情感在假新闻检测中的重要性，或通过分析虚假内容关联的情感特征，或利用情感与情绪特征进行分类。然而，这带来了新的安全漏洞——随着大语言模型（LLMs）的发展，攻击者可通过操纵情感特征规避检测器。虽有少数研究探讨了LLMs生成的对抗样本，但主要聚焦于新闻发布者的写作风格等表层特征，情感操纵这一关键漏洞仍未被充分探索。本文系统研究了当前最先进的假新闻检测器在情感操纵下的鲁棒性，并提出AdSent框架——一种能确保原始新闻与情感篡改新闻在真实性判断上保持一致的抗情感干扰检测框架。具体而言，我们（1）提出基于LLMs的受控情感对抗攻击方法；（2）分析情感偏移对检测性能的影响，发现情感改变会显著降低检测模型性能，模型普遍存在将中性文章判为真实、非中性文章判为虚假的偏见；（3）设计了一种新颖的情感无关训练策略以增强模型对抗此类干扰的鲁棒性。在三个基准数据集上的大量实验表明，AdSent在检测精度与鲁棒性上均显著优于现有基线模型，并能有效泛化至未见数据集及对抗场景。

---

## 2. 大语言模型在法律应用中的评估：挑战、方法与未来方向

- **原文链接**: http://arxiv.org/abs/2601.15267v1
- **发布日期**: 2026-01-21
- **摘要**:

大型语言模型正日益融入法律应用领域，涵盖司法决策支持、法律实务辅助及公共法律服务等多个场景。尽管这类模型在处理法律知识与任务方面展现出巨大潜力，但其在实际法律场景中的部署引发了超越表层准确性的深层关切，涉及法律推理过程的严谨性以及公平性、可靠性等可信度问题。因此，对大型语言模型在法律任务中的表现进行系统性评估，已成为其负责任应用的关键前提。

本综述立足于真实法律实践，系统梳理了法律领域大型语言模型评估面临的核心挑战。我们深入剖析了评估过程中涉及的主要难点，包括结果正确性、推理可靠性及系统可信度三大维度。基于这些挑战，本文从任务设计、数据集构建与评估指标三个层面，对现有评估方法与基准测试体系进行了系统性梳理与分类。进一步地，我们探讨了当前方法应对这些挑战的有效程度，指出其局限性，并展望未来研究方向，以期为法律领域构建更贴近现实、更具可靠性且深植于法律根基的大型语言模型评估框架。

---

## 3. 脚本与格式对大型语言模型数学能力的影响

- **原文链接**: http://arxiv.org/abs/2601.15251v1
- **发布日期**: 2026-01-21
- **摘要**:

大型语言模型（LLM）在基础算术方面已展现出令人瞩目的熟练度，在标准数值任务上达到了媲美人类的水平。然而，当数值表达方式偏离其训练语料库中的主流规范时，这些模型的表现却鲜少受到关注。本研究系统考察了多种数字书写系统与格式下的数值推理能力。我们发现，当数值输入以训练数据中较少出现的书写形式或格式呈现时，即使底层数学推理逻辑完全相同，LLM的准确率仍会大幅下降。进一步研究表明，通过针对性提示策略——如少样本提示和显式数字映射——能够显著缩小这种性能差距。我们的研究结果揭示了多语言数值推理中一个被忽视的挑战，并为可靠运用LLM解析、处理和生成不同数字书写系统与格式的数值提供了切实可行的解决方案。

---

